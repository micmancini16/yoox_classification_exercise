{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificazione YOOX Maniche con Keras\n",
    "\n",
    "## Importazione Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparazione dati\n",
    "\n",
    "Definisco una classe astratta per generici dataset di classificazione immagini, e la estendo con un'implementazione relativa al dataset trattato. Nell'implementazione, le classi vengono assegnate alle immagini in base alla cartella in cui esse sono contenute. Tramite la funzione load_data, virtuale pura in ClassificationDataset, implementata nelle classi derivate, carico i dati e li splitto, randomicamente, tra training e test set in base al parametro train_imgs_to_test_imgs_ratio. Di default, inserisco circa il 70% delle immagini nel training set, il restante nel test set. Lo shuffling verrà gestito dal generatore.\n",
    "Infine, calcolo dei pesi per ogni classe inversamente proporzionali alla frequenza delle loro istanze nel dataset, dando così maggiore importanza alle classi meno frequenti. Ad esempio, la classe 'monospalla' risulta meno frequente rispetto alle altre. I pesi saranno poi utilizzati in fase di training.\n",
    "\n",
    "Si assume che il dataset sia stato estratto in una cartella con path relativo 'data/dati_maniche'. È possibile settare il parametro root_dir da costruttore per utilizzare altre directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset(object):\n",
    "    \"\"\"\n",
    "    Generic interface for classification datasets\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, resize_to = None, train_imgs_to_test_imgs_ratio = 0.7):\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "        self.class_str_names = []\n",
    "        self.class_weights = {} #dict to store class weights for unbalanced datasets\n",
    "        self.n_of_imgs_per_class = {}\n",
    "\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "        #\n",
    "        self.x_test = []\n",
    "        self.y_test = []\n",
    "\n",
    "        self.total_n_of_imgs = 0\n",
    "\n",
    "        self.load_data(resize_to, train_imgs_to_test_imgs_ratio)\n",
    "\n",
    "    def load_data(self, resize_to, train_imgs_to_test_imgs_ratio):\n",
    "        raise NotImplementedError\n",
    "    def get_training_set(self):\n",
    "        return self.x_train,self.y_train\n",
    "    def get_test_set(self):\n",
    "        return self.x_test,self.y_test\n",
    "    def get_input_shape(self):\n",
    "        return self.x_train[0].shape\n",
    "    \n",
    "class YOOX_ManicheDataset(ClassificationDataset):\n",
    "    \"\"\"\n",
    "    Data archive is assumed to be stored and unzipped into a directory called 'data'\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir = 'data/dati_maniche', resize_to = None, train_imgs_to_test_imgs_ratio = 0.7):\n",
    "        super(YOOX_ManicheDataset,self).__init__(root_dir, resize_to, train_imgs_to_test_imgs_ratio)\n",
    "\n",
    "    def load_data(self,resize_to,train_imgs_to_test_imgs_ratio):\n",
    "\n",
    "        #Each directory in the root dir represents a single class\n",
    "        dir_paths = [dir_path for dir_path in glob(os.path.join(self.root_dir,'*')) if os.path.isdir(dir_path)]\n",
    "        self.class_str_names = [path.split('/')[-1] for path in dir_paths]\n",
    "        self.num_classes = len(self.class_str_names)\n",
    "\n",
    "        for class_idx, class_dir in enumerate(dir_paths):\n",
    "            file_list = glob(os.path.join(class_dir,'*.png'))\n",
    "\n",
    "            self.n_of_imgs_per_class[class_idx] = len(file_list)\n",
    "            self.total_n_of_imgs += self.n_of_imgs_per_class[class_idx]\n",
    "\n",
    "            for file in file_list:\n",
    "                #Read and normalize input in [0..1] range\n",
    "                img = cv2.imread(file,1)/255.\n",
    "\n",
    "                #Set background white to 0, as if it was the result of zero-padding (slighty improved accuracy when done)\n",
    "                img[(img==1).all(axis=2)] = 0\n",
    "\n",
    "                if resize_to is not None:\n",
    "                    img = cv2.resize(img, resize_to)\n",
    "\n",
    "                #Create one-hot encoding with numpy basic functions\n",
    "                label = np.zeros(self.num_classes)\n",
    "                label[class_idx] = 1\n",
    "\n",
    "                #Split data randomly between train and test sets\n",
    "                if np.random.random() < train_imgs_to_test_imgs_ratio:\n",
    "                    self.x_train.append(img)\n",
    "                    self.y_train.append(label)\n",
    "                else:\n",
    "                    self.x_test.append(img)\n",
    "                    self.y_test.append(label)\n",
    "\n",
    "        self.x_train = np.asarray(self.x_train)\n",
    "        self.y_train = np.asarray(self.y_train)\n",
    "        self.x_test = np.asarray(self.x_test)\n",
    "        self.y_test = np.asarray(self.y_test)\n",
    "\n",
    "        #Compute weights for unbalanced classes\n",
    "        for i in range(self.num_classes):\n",
    "            self.class_weights[i] = 1.0 - self.n_of_imgs_per_class[i] / self.total_n_of_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definizione Modello\n",
    "\n",
    "Step 3: Definisco un semplice modello convoluzionale per la classificazione delle immagini usando le API dei modelli sequenziali di Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(object):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.graph = None\n",
    "        self.define_graph(input_shape,num_classes)\n",
    "    def define_graph(self,input_shape,num_classes):\n",
    "        raise NotImplementedError\n",
    "    def preprocess_img(self,img):\n",
    "        #Ovveride for model-specific preprocessing\n",
    "        return img\n",
    "\n",
    "class BaseConvClassifier(ClassificationModel):\n",
    "    def __init__(self, input_shape,num_classes):\n",
    "        super(BaseConvClassifier,self).__init__(input_shape,num_classes)\n",
    "    def define_graph(self,input_shape,num_classes):\n",
    "        self.graph = tf.keras.Sequential()\n",
    "\n",
    "        self.graph.add(tf.keras.layers.Conv2D(16, (3, 3), padding='same',\n",
    "                                         input_shape=input_shape))\n",
    "        self.graph.add(tf.keras.layers.Activation('relu'))\n",
    "        self.graph.add(tf.keras.layers.Conv2D(16, (3, 3), padding='same'))\n",
    "        self.graph.add(tf.keras.layers.Activation('relu'))\n",
    "        self.graph.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.graph.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "        self.graph.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same'))\n",
    "        self.graph.add(tf.keras.layers.Activation('relu'))\n",
    "        self.graph.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same'))\n",
    "        self.graph.add(tf.keras.layers.Activation('relu'))\n",
    "        self.graph.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        self.graph.add(tf.keras.layers.Flatten())\n",
    "        self.graph.add(tf.keras.layers.Dense(512))\n",
    "        self.graph.add(tf.keras.layers.Activation('relu'))\n",
    "        self.graph.add(tf.keras.layers.Dropout(0.5))\n",
    "        self.graph.add(tf.keras.layers.Dense(num_classes))\n",
    "        self.graph.add(tf.keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definizione Viewer\n",
    "\n",
    "Definisco poi un'interfaccia per la visualizzazione dei dati. L'implementazione è basata sulle API OpenCV. (Non ho utilizzato matplotlib per semplicità a causa di alcuni problemi di dipendenze sul mio computer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Viewer(object):\n",
    "    def show_images_with_labels(self, images, labels, label_str_descriptions, num_images_to_show = 1, select_imgs_at_random = True,title=\"\"):\n",
    "        pass\n",
    "    def print_dataset_stats(self,data):\n",
    "        assert(isinstance(data,ClassificationDataset))\n",
    "\n",
    "        print(\"Images per class:{}\".format(data.n_of_imgs_per_class))\n",
    "        print(\"Total images in dataset:{}\".format(data.total_n_of_imgs))\n",
    "        print(\"Images in training set: {}\".format(len(data.x_train)))\n",
    "        print(\"Images in test set: {}\".format(len(data.x_test)))\n",
    "    def print_accuracy_result(self,accuracy):\n",
    "        print(\"Accuracy: {}\".format(accuracy))\n",
    "\n",
    "class OpenCV_Viewer(Viewer):\n",
    "    \"\"\"\n",
    "    Show images with OpenCV\n",
    "    \"\"\"\n",
    "    def show_images_with_labels(self, images, labels, label_str_descriptions, num_images_to_show = 1, select_imgs_at_random = True, title=\"\"):\n",
    "\n",
    "        if select_imgs_at_random:\n",
    "            imgs_to_show = [random.randint(0,len(images)-1) for i in range(num_images_to_show)]\n",
    "        else:\n",
    "            imgs_to_show = range(num_images_to_show)\n",
    "        for i, idx in enumerate(imgs_to_show):\n",
    "            str_description = label_str_descriptions[np.argmax(labels[idx])]\n",
    "            cv2.imshow(\"{}: {}\".format(i, len(imgs_to_show),title,str_description),\n",
    "                       cv2.cvtColor((images[idx]*255).astype(np.uint8),cv2.COLOR_BGR2RGB))\n",
    "            cv2.waitKey(10)\n",
    "    \n",
    "        cv2.waitKey(15000) #Wait 15 seconds\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impostazione training e test\n",
    "\n",
    "Imposto una classe Trainer con un metodo statico 'start' per avviare l'addestramento. Il metodo prende come argomento le istanze del dataset e del modello, l'istanza di un oggetto DataGenerator(uno di default o un'eventuale estensione) oltre a vari parametri per l'addestramento. Analogalmente, imposto una classe Tester. Utilizzo un riferimento al Viewer per stampare e visualizzare dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    @classmethod\n",
    "    def start(cls,data,model,loss,optimizer,eval_metrics,datagen,batch_size,epochs, viewer=Viewer()):\n",
    "        assert(isinstance(data, ClassificationDataset))\n",
    "        assert(isinstance(model, ClassificationModel))\n",
    "\n",
    "        viewer.print_dataset_stats(data)\n",
    "\n",
    "        x_train, y_train = data.get_training_set()\n",
    "\n",
    "        #Show samples through the viewer\n",
    "        viewer.show_images_with_labels(x_train, y_train, data.class_str_names, num_images_to_show=8,select_imgs_at_random=True,title=\"Train Label\")\n",
    "\n",
    "        #Compile graph\n",
    "        model.graph.compile(loss=loss,optimizer=optimizer,metrics=eval_metrics)\n",
    "        #Compute stats for the generator, if necessary\n",
    "        datagen.fit(x_train)\n",
    "        #Train\n",
    "        model.graph.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size, shuffle=True),\n",
    "                                  epochs=epochs, workers=4, class_weight=data.class_weights)\n",
    "class Tester(object):\n",
    "    @classmethod\n",
    "    def start(cls,data,model,viewer=Viewer()):\n",
    "        x_test,y_test = data.get_test_set()\n",
    "        predictions = model.graph.predict(x_test)\n",
    "\n",
    "        viewer.show_images_with_labels(x_test,predictions,data.class_str_names,num_images_to_show=8,select_imgs_at_random=True,title=\"Prediction\")\n",
    "\n",
    "        accuracy = model.graph.evaluate(x_test,y_test,batch_size=32)[1]\n",
    "        viewer.print_accuracy_result(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main method\n",
    "\n",
    "Infine, imposto il main, instanziando il dataset, il modello, il generatore e il viewer. \n",
    "\n",
    "Il resize delle immagini tramite la classe Dataset mi è stato necessario per limitazione della RAM disponibile. Un approccio alternativo avrebbe potuto prevedere un'implementazione del dataset che caricasse in RAM, nei campi x_train, x_test, i path delle immagini, e un'estensione del generatore custom in grado di leggere, per ogni batch, i path e caricare le immagini dinamicamente. Tale approccio avrebbe avuto lo svantaggio di causare frequenti letture in memoria secondaria. Se il resizing fosse stato richiesto dal modello (es. modelli tipo VGG richiedono input di dimensione fissata), sarebbe stato più opportuno implementarlo nel metodo preprocess_img della classe Model, che viene passata come parametro al generatore.\n",
    "\n",
    "Con i parametri così impostati, ho riscontrato una accuracy sul test set pari a circa il 90.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cbc609f79eb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOOX_ManicheDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresize_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseConvClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n\u001b[1;32m      6\u001b[0m             \u001b[0mhorizontal_flip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ec417f97a200>\u001b[0m in \u001b[0;36mget_input_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_input_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mYOOX_ManicheDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassificationDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    data = YOOX_ManicheDataset(resize_to=(64,64))\n",
    "    model = BaseConvClassifier(data.get_input_shape(),data.num_classes)\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            horizontal_flip=True,\n",
    "            preprocessing_function=model.preprocess_img,\n",
    "            validation_split=0.2)\n",
    "\n",
    "    viewer = OpenCV_Viewer()\n",
    "\n",
    "    Trainer.start(data,model,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adam(),\n",
    "                  eval_metrics=['accuracy'],\n",
    "                  datagen=datagen,\n",
    "                  batch_size=16,\n",
    "                  epochs=5,\n",
    "                  viewer=viewer)\n",
    "\n",
    "\n",
    "    print(\"**************TEST******************\")\n",
    "    Tester.start(data,model,viewer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
